# Highlight Research Articles

A curated list of the most cited machine learning / deep learning articles, papers, blogs, ..

Inspired by [awesome-python](https://github.com/vinta/awesome-python).

---

[TOC]

## Techniques

* [Face Recognition](#)
	* [Blog - BLCV's Series](http://blcv.pl/static/tag/face-recogition) - Face Recognition Technology using Computer Vision
* [Image Similarity Search](#)
	* [Blog - Medium](https://blog.insightdatascience.com/the-unreasonable-effectiveness-of-deep-learning-representations-4ce83fc663cf) - Building an image search service from scratch
	* [Blog - Medium](https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511) - CBIR Using Convolutional Denoising Autoencoder
* [CNN](#)
	* [Blog - Medium](https://towardsdatascience.com/3-small-but-powerful-convolutional-networks-27ef86faa42d) - 3 Small but Powerful Convolutional Networks
	* [Note - GithubGist](https://gist.github.com/zeyademam/0f60821a0d36ea44eef496633b4430fc) - Troubleshooting Convolutional Neural Networks
* [Multi-Task Learning](#) 
	* [Blog - Fast Forward Labs](https://blog.fastforwardlabs.com/2018/07/24/ff08-launch.html) - New Research on Multi-Task Learning
	* [Blog - Ruder](http://ruder.io/multi-task) - An Overview of Multi-Task Learning in Deep Neural Networks

## Statistics

* [Probabilistic](#)
	* [Blog - Seeing Theory](https://students.brown.edu/seeing-theory/basic-probability/index.html) - Basic Probability

## Optimizations

* [Gradient Descent - Ruder](http://ruder.io/optimizing-gradient-descent) - An Overview of Gradient Descent Optimization Algorithms

## Loss

* [Triplet Loss](#)
	* [Blog - Olivier Moindrot](https://omoindrot.github.io/triplet-loss) - Triplet Loss and Online Triplet Mining in TensorFlow
* [CTC Loss](#)
	* [Blog - Distill](https://distill.pub/2017/ctc)
* [Cross-Entropy Loss](#)
	* [Blog - Jupyter](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss) - A Friendly Introduction to Cross-Entropy Loss

## NLPs

* [Blogs and Bloggers](#)
	* [Delip Rao](http://deliprao.com/archives/294) - Design Patterns for Production NLP Systems
* [Attention Mechanism]()
	* [Blog - Illustrated Transformer](https://jalammar.github.io/illustrated-transformer)
	* [Blog - Attention Explained](http://nlp.seas.harvard.edu/2018/04/03/attention.html) - Harvard NLP
* [Embeddings]()
	* [Blog - Introduction](http://hunterheidenreich.com/blog/intro-to-word-embeddings) - Introduction to Word Embeddings
	* [Blog - Introduction](http://gavagai.se/blog/2015/09/30/a-brief-history-of-word-embeddings) - A Brief History Of Word Embeddings
	* [Blog - Ruder](http://ruder.io/word-embeddings-1)
	* [Word2Vec](#)
		* [CBOW](#)
		* [Skip-gram](#)
	* [GloVe](#)
	* [FastText](#)
	* [Poincare Embedding](#)
	* [ELMo](#)
	* [Doc2Vec](#)
	* [Char2Vec - Minimaxir](https://minimaxir.com/2017/04/char-embeddings)
* [Text Classification](#)
* [Sentiment Analysis](#)
* [Coreference Resolution](#)
* [Topic Modeling]()
	* [Blog - Introduction](https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05) - Covered LSA, pLSA, LDA, LDA2Vec
* [NER](#)
* [POS-Tagging](#)
* [NMT](#)
	* [Blog - Saleforce](https://einstein.ai/research/non-autoregressive-neural-machine-translation) - Fully-parallel text generation for neural machine translation
* [Q&A](#)
* [Text Summarization](#)
	* [Blog - Medium](https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1) - Unsupervised Text Summarization using Sentence Embeddings

## Computer Visions

* [Object Detection](#)
	* [RCNN](#)
	* [Fast-RCNN](#)
	* [Faster-RCNN](#)
		* [Blog - Tryolabs](https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection) - Down the rabbit hole of modern object detection
	* [Yolo](#)
	* [SSD](#)
* [Transformation](#)
	* [STN](#)
		* [Paper](https://arxiv.org/abs/1506.02025) - Spatial Transformer Networks
		* [Blog - Medium](https://towardsdatascience.com/convnets-series-spatial-transformer-networks-cff47565ae81) - ConvNets Series: Spatial Transformer Networks
		* [Blog - Kevin Zakka](https://kevinzakka.github.io/2017/01/10/stn-part1) - Deep Learning Paper Implementations: Spatial Transformer Networks
		* [Tutorial - Pytorch's doc](https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)
* [OCR](#)
	* [Tools](#)
		* [ABBYY](#)
		* [Tesseract](#)
	* [Blog - Tutorial](http://www.aosabook.org/en/500L/optical-character-recognition-ocr.html) - 500 lines or less: OCR tutorial from scratch

## Machine Learning 

* [Decision Tree](#)
	* [Blog](https://brohrer.github.io/how_decision_trees_work.html) - How decision tree works
* [Gradient Boosting](#)
	* [Blog](http://explained.ai/gradient-boosting/index.html) - How to explain gradient boosting

## Neural Networks

* [Techniques](#)
	* [Learning Rate](#)
		* [Blog - Jeremy Jordan](https://www.jeremyjordan.me/nn-learning-rate) - Setting the learning rate of your neural network
		* [Blog - Medium](https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b) - Improving the way we work with learning rate
* [FNN](#)
* [CNN](#)
* [RNN](#)
* [LSTM](#)
	* [Blog - Colab](http://colah.github.io/posts/2015-08-Understanding-LSTMs) - Understanding LSTM Networks
	* [Blog - Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness) - The Unreasonable Effectiveness of Recurrent Neural Networks
	* [Blog - Edwin Chen](http://blog.echen.me/2017/05/30/exploring-lstms) - Exploring LSTMs
* [BiLSTM](#)
* [mLSTM](#)
	* [Paper](https://arxiv.org/abs/1609.07959)
	* [Blog](https://florianwilhelm.info/2018/08/multiplicative_LSTM_for_sequence_based_recos) - Multiplicative LSTM for Sequence-Based Recommenders
* [AutoEncoder](#)
* [GAN](#)
* [GCN](#)
	* [Blog - Thomas Kipf](https://tkipf.github.io/graph-convolutional-networks) - Graph Convolution Networks
* [GNN](#)
* [CRNN](https://arxiv.org/abs/1507.05717)
	* [Paper](https://arxiv.org/abs/1507.05717)
	* [Github - Pytorch](https://github.com/meijieru/crnn.pytorch)
	* [CLC loss](https://distill.pub/2017/ctc)
	* [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)
		* [Github - Pytorch](https://github.com/sbillburg/CRNN-with-STN) - CRNN with STN
* [CTPN](https://arxiv.org/abs/1609.03605)
	* [Paper](https://arxiv.org/abs/1609.03605)
* [SqueezeNet](#)
	* [Paper](https://arxiv.org/abs/1602.07360v4)
* [ShuffleNet](#)
	* [Paper](https://arxiv.org/abs/1707.01083v2)
* [MobileNet](#)
	* [Paper](https://arxiv.org/abs/1704.04861v1)

## Embedding (a.k.a awesome2vec)

* [Loc2Vec](https://www.sentiance.com/2018/05/03/loc2vec-learning-location-embeddings-w-triplet-loss-networks)
* [Url2Vec](https://github.com/chrisPiemonte/url2vec)

## Recommender Systems

## Sequence Modeling

## Sound Recognition

* [Website - MIR](https://musicinformationretrieval.com) - Instructional notebooks on music information retrieval.
	* [Github](https://github.com/stevetjoa/musicinformationretrieval.com)
* [Q&A - Quora](https://www.quora.com/What-are-some-common-features-used-in-audio-based-classification) - What are some common features used in audio-based classification?
* [Notebook Tutorial - Github](https://github.com/jaron/deep-listening) - Deep Learning experiments for audio classification
* [Tutorial](https://aqibsaeed.github.io/2016-09-03-urban-sound-classification-part-1) - Urban Sound Classification
* [Tutorial](https://medium.com/iotforall/sound-classification-with-tensorflow-8209bdb03dfb) - Sound Classification with Tensorflow

## Speech Recognition

* [Medium - Kaggle](https://towardsdatascience.com/kaggle-tensorflow-speech-recognition-challenge-b46a3bca2501) - Kaggle Tensorflow Speech Recognition Challenge

## Transfer Learning

* [Blog - Feedly](https://blog.feedly.com/transfer-learning-in-nlp) - Transfer Learning in NLP with ULMFit
* [Blog - Medium](https://medium.com/explorations-in-language-and-learning/transfer-learning-in-nlp-2d09c3dfaeb6) - Transfer Learning in NLP
* [Blog - Medium](https://towardsdatascience.com/transfer-learning-using-differential-learning-rates-638455797f00) - Transfer Learning using Differential Learning Rate
* [Blog](https://rmarcus.info/blog/2017/10/04/rfk.html) - The often-overlooked random forest kernel | Transfer Learning using Random Forest
* [Pytorch](#)
	* [Fine-tuning - Notebook](https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch) - Part 1
	* [Fine-tuning - Notebook](https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial) - Part 2

## Continuous Learning

## Visualisation

* [Interactive Machine Learning list](https://p.migdal.pl/interactive-machine-learning-list)
* [Neural Network Demo](https://phiresky.github.io/neural-network-demo)
* [Bachpropagation by Google Developers](https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll)
* [Hands-on ML and its related books](https://anvaka.github.io/greview/hands-on-ml/1)

## Project Blueprint 

* [Tensorflow Project Template](https://github.com/MrGemy95/Tensorflow-Project-Template)
	* [Keras Version](https://github.com/Ahmkel/Keras-Project-Template)
	* [Pytorch Version](https://github.com/victoresque/pytorch-template)

---

to be continued ...
